{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcualte the actual Perturbation Interactions  \n",
    "1.) Extract all perturbation vectors\n",
    "\n",
    "Perfore calculating the actual interaction one need to consider:  \n",
    "2.) Check Drug Decay  (some drugs show symptoms of decay e.g. oxidiation --> less potency over time)  \n",
    "3.) Check CellCount  (if ther cellcount is below a certain number not statistical significant assumption can be made regarding the cell morphology)  \n",
    "\n",
    "To calculate meaningful interaction one need to check if the single and combination perturbation are significantly different from DMSO random fluctuation  \n",
    "4.) Check significance of single drugs   \n",
    "\n",
    "Finally drug interaction can be calculated  \n",
    "5.) Check per Single Drug fluctuation (alpha/beta and gamma) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary python modules\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "from scipy.spatial import distance as dis\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from matplotlib import pylab as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract perturbation vectors\n",
    "Load both the n-dim perturbation vectors for cells being (i) untreated and (ii) treated with any single or combination of drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract the perturbation vectors as well as DMSO vectors (split per batch to reduce per batch effects)\n",
    "a.) drug_perturbation_vectors (drug perturbations)\n",
    "b.) dmso (DMSO)\n",
    "'''\n",
    "\n",
    "\n",
    "# Load all the drug perturbation vectors\n",
    "path = '../data/Calculate_Interactions/All_Vectors_Combined.csv'\n",
    "fp = open(path)\n",
    "\n",
    "# Get a list of all features\n",
    "features = fp.readline().split(',')[1:]\n",
    "numfeatures = len(features)\n",
    "\n",
    "# Final dictionaries containing the individual perturbation vectors\n",
    "drug_perturbation_vectors = {'Batch1':{},'Batch2':{}}\n",
    "dmso = {'Batch1':[],'Batch2':[]}\n",
    "\n",
    "All_CLOUDs = set()\n",
    "# Go threw the file and create DMSO and drug_perturbation_vectors\n",
    "# DMSO per batch\n",
    "# drug_perturbation_vectors per Batch with full identifier\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    drug1, drug2 = tmp[0].split('_')[0].split('|')\n",
    "    well = tmp[0].split('_')[1]\n",
    "    plate = tmp[0].split('_')[2]\n",
    "    \n",
    "    values = list(np.float_(tmp[1:]))\n",
    "    \n",
    "    if int(plate) < 1315065:\n",
    "        if drug1 == 'DMSO':\n",
    "            dmso['Batch1'].append(values)\n",
    "        drug_perturbation_vectors['Batch1'][drug1+','+drug2+','+plate+','+well] = values\n",
    "\n",
    "            \n",
    "    else:\n",
    "        if drug1 == 'DMSO':\n",
    "            dmso['Batch2'].append(values)\n",
    "        drug_perturbation_vectors['Batch2'][drug1+','+drug2+','+plate+','+well] = values\n",
    "        \n",
    "        #If at least in at least any of either two batches\n",
    "        All_CLOUDs.add(drug1)\n",
    "\n",
    "        \n",
    "all_all_clouds = []\n",
    "for i in range(1,268):\n",
    "    all_all_clouds.append('CLOUD'+str(i).zfill(3))\n",
    "    \n",
    "#Get list of All_CLOUDs, this number is smaller than the original number due to some drugs not being transformer correctly or other problems\n",
    "All_CLOUDs.remove('DMSO')\n",
    "All_CLOUDs.remove('PosCon')\n",
    "\n",
    "#plot number of clouds found\n",
    "All_CLOUDs = list(All_CLOUDs)\n",
    "All_CLOUDs.sort()\n",
    "print 'Number of drugs that have at least one correct well: %d' %len(All_CLOUDs)\n",
    "    \n",
    "print len(drug_perturbation_vectors['Batch2'][drug_perturbation_vectors['Batch2'].keys()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Drug Decay\n",
    "Check if some of the drugs decayed over the course of the screen. This can be validated by checking if drugs have a different cytotoxicity between 'early' spotted plates compared to 'later' spotted plates. Plates with lower plate IDs are earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both thresholds need to be true to set a drug as decayed during experiment; threshold_decay is steepness and threshold_MaxDifference absolute difference\n",
    "threshold_decay = 0.05\n",
    "threshold_MaxDifference = 0.3\n",
    "\n",
    "\n",
    "# Load all the drug decay regressions\n",
    "# Created by checking the single drug responses over the different plates (there is a temporal context between plate 1 and 123)\n",
    "# One is interested both in the decay as well as the maximum change e.g. if gradient between 0.1 to 0.2, still ok\n",
    "# Create a dic that tells about the status of drug decay i.e. True if drug WORKED CORRECTLY\n",
    "path = '../data/Calculate_Interactions/DrugDecay_Combined.csv'\n",
    "fp = open(path)\n",
    "fp.next()\n",
    "drug_decay = {}\n",
    "batch1_Failed = 0\n",
    "batch2_Failed = 0\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    \n",
    "    batch1_decay = float(tmp[1])\n",
    "    batch1_diff = float(tmp[2])\n",
    "    \n",
    "    batch2_decay = float(tmp[3])\n",
    "    batch2_diff = float(tmp[4])\n",
    "    \n",
    "    \n",
    "    batch1_Status = True\n",
    "    if batch1_decay >= threshold_decay and batch1_diff >= threshold_MaxDifference:\n",
    "        batch1_Status = False\n",
    "        batch1_Failed += 1\n",
    "        \n",
    "    batch2_Status = True\n",
    "    if batch2_decay >= threshold_decay and batch2_diff >= threshold_MaxDifference:\n",
    "        batch2_Status = False\n",
    "        batch2_Failed += 1\n",
    "    \n",
    "    \n",
    "    drug_decay[tmp[0]] = {'Batch1':batch1_Status,'Batch2':batch2_Status}\n",
    "fp.close()\n",
    "\n",
    "print 'Number of drugs that decayed in batch1: %d' %batch1_Failed\n",
    "print 'Number of drugs that decayed in batch2: %d' %batch2_Failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Cell Count\n",
    "Check if the individual wells have enough cells to be statistically valid. Having wells with only e.g. 5 cells can all be outliers or somehow else be errourous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimum cells allowed\n",
    "cutoff_min_cells = 30\n",
    "\n",
    "#per well count\n",
    "well_cell_count = {}\n",
    "\n",
    "#number of wells below cutoff_min_cells\n",
    "empty_well = 0\n",
    "\n",
    "#go through CellCount file to find wells with too little cells\n",
    "path = '../data/Calculate_Interactions/All_CellCounts_Combined.csv'\n",
    "fp = open(path)\n",
    "fp.next()\n",
    "for line in fp:\n",
    "    tmp = line.strip().split(',')\n",
    "    num_cells = float(tmp[4])\n",
    "    well_cell_count[tmp[0]+','+tmp[1]+','+tmp[2]+','+tmp[3]] = {'Number':num_cells,'Worked':tmp[5]}\n",
    "    \n",
    "#Mean number of cells (DMSO and Perturbations)\n",
    "print 'Mean number of cells in Batch1: %f'  %np.mean([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) < 1315065])\n",
    "print 'Mean number of cells in Batch1: %f'  %np.mean([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) >= 1315065])\n",
    "\n",
    "#Number of empty wells (DMSO and Perturbations)\n",
    "print 'Number of empty wells in Batch1: %d'  %len([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) < 1315065 and well_cell_count[x]['Number'] < cutoff_min_cells])\n",
    "print 'Number of empty wells in Batch2: %d'  %len([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) >= 1315065 and well_cell_count[x]['Number'] < cutoff_min_cells])\n",
    "\n",
    "#Get the 90 percentile of DMSO cellcount\n",
    "DMSO_CellCount = {}\n",
    "DMSO_CellCount['Batch1']= np.percentile([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) < 1315065 and x.split(',')[0] == 'DMSO'],90)\n",
    "DMSO_CellCount['Batch2']= np.percentile([well_cell_count[x]['Number'] for x in well_cell_count if int(x.split(',')[2]) >= 1315065 and x.split(',')[0] == 'DMSO'],90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which Drugs should be removed from analysis  (too few cells, transfer problems etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of drugs that kill too many cells to do morphological analysis with them (Remove only for Morphology Analysis)\n",
    "killing_drugs = {'Batch1':[],'Batch2':[]}\n",
    "\n",
    "#this drugs must be removed from further analysis (Both the CellCount and Morphology Analysis)\n",
    "drugs_to_remove = {'Batch1':[],'Batch2':[]}\n",
    "\n",
    "for cloud in All_CLOUDs:\n",
    "    for b in ['Batch1','Batch2']:\n",
    "        \n",
    "        #Check if enough replicates exist\n",
    "        enough_replicates_status = len(drug_vectors_WithoutOutliers[b][cloud]) >= 3\n",
    "        \n",
    "        #Get result from drug decay analayis\n",
    "        drug_decay_status = drug_decay[cloud][b]\n",
    "        \n",
    "        #Check if both are good\n",
    "        if enough_replicates_status and drug_decay_status:   \n",
    "            continue\n",
    "        else:\n",
    "          \n",
    "            #if the drug does not decay and has enough working wells not image problems, you can use it still for CellCount Anlaysis (again if at least 3 wells)\n",
    "            if drug_decay_status:\n",
    "                number_replicates = len([x for x in drug_perturbation_vectors[b] if cloud+',DMSO' in x])\n",
    "                \n",
    "                if number_replicates >= 3:\n",
    "                    #print '==> can be used a \"killing drug\"'\n",
    "                    killing_drugs[b].append(cloud)\n",
    "                else:\n",
    "                    drugs_to_remove[b].append(cloud)\n",
    "            else:\n",
    "                drugs_to_remove[b].append(cloud)\n",
    "\n",
    "print 'Drugs to remove:'\n",
    "print drugs_to_remove\n",
    "\n",
    "print 'Cytotoxic drugs/non usable morphological features:'\n",
    "print killing_drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check which single Drugs are significantly morphologically changed\n",
    "Compared to DMSO random cell intrinsic morphological fluctuation (compare via Mahalanobis distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Easy Outlier detection\n",
    "def reject_outliers_2(data, m=6.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d / (mdev if mdev else 1.)\n",
    "    return s < m\n",
    "    #return [data[i] for i in range(0, len(data)) if s[i] < m]\n",
    "\n",
    "    \n",
    "\n",
    "def Create_Single_Drug_Vectors():\n",
    "    '''\n",
    "    Extracts the individual drug perturbation vectors (for the two batches separate).\n",
    "    Outliers e.g. one replicate that is too different from the remaining 5/6 will be removed.\n",
    "    \n",
    "    Only calculated for significant singles\n",
    "    '''\n",
    "    \n",
    "    drug_vectors = {'Batch1':{},'Batch2':{}}\n",
    "    for cloud in All_CLOUDs:\n",
    "        for b in ['Batch1','Batch2']:    \n",
    "\n",
    "\n",
    "            drug_wells = [x for x in drug_perturbation_vectors[b] if cloud+',DMSO' in x and well_cell_count[x]['Number'] > cutoff_min_cells]\n",
    "\n",
    "           \n",
    "            if len(drug_wells) < 3:\n",
    "                drug_vectors[b][cloud] = {}\n",
    "            else:\n",
    "                drug_well_values = []\n",
    "                for well in drug_wells:\n",
    "                    drug_well_values.append(drug_perturbation_vectors[b][well])\n",
    "\n",
    "                drug_well_values = np.array(drug_well_values)\n",
    "\n",
    "                drug_EucledianDistances = []\n",
    "                drug_names = []\n",
    "                drug_values = []\n",
    "                for s1_a,label_a in zip(drug_well_values,drug_wells):\n",
    "                    tmp = []\n",
    "                    for s1_b,label_b in zip(drug_well_values,drug_wells):\n",
    "                        sim = np.linalg.norm(s1_a - s1_b) \n",
    "                        tmp.append(sim)\n",
    "\n",
    "                    drug_EucledianDistances.append(np.mean(tmp))\n",
    "                    drug_names.append(label_a)\n",
    "                    drug_values.append(s1_a)\n",
    "\n",
    "                \n",
    "               \n",
    "                good_rows = reject_outliers_2(drug_EucledianDistances)\n",
    "                keep_values = [drug_values[x] for x in range(0,len(drug_values)) if good_rows[x]]\n",
    "                keep_names = [drug_names[x] for x in range(0,len(drug_names)) if good_rows[x]]\n",
    "\n",
    "                drug_vectors[b][cloud] = {}\n",
    "                for val, lab in zip(keep_values,keep_names):\n",
    "                    drug_vectors[b][cloud][lab] = val\n",
    "\n",
    "    return drug_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dictionary for all single drugs, and remove obvious outliers\n",
    "Outliers are detected by first calculating the mean eucledian distance of a point to all other points and then performing an MAD outlier detection\n",
    "'''\n",
    "drug_vectors_WithoutOutliers = Create_Single_Drug_Vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Random_Distribution_DMSO(DMSO_Wells,num_pseudo_treatments=4):\n",
    "    '''\n",
    "    Calculate random mahalanbis distances between randomly picked DMSO wells. Computing these values beforehand significantly improves performance, else for each significance calculation\n",
    "    this random distribution would be need to be calculated.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #Fit a PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(DMSO_Wells)\n",
    "\n",
    "    #Take only as many principel components so taht 90% of the variance can be explained\n",
    "    variances = pca.explained_variance_ratio_\n",
    "    total = 0\n",
    "    use_components = 0\n",
    "    for v in variances:\n",
    "        total = total + v\n",
    "        use_components += 1\n",
    "        if total > 0.9:\n",
    "            break\n",
    "\n",
    "    #Use at least 2 components\n",
    "    if use_components <= 1:\n",
    "        use_components = 2\n",
    "    \n",
    "    #Fit the space to the selected amount of components and transform the data\n",
    "    pca = PCA(n_components=use_components)\n",
    "    pca.fit(DMSO_Wells)\n",
    "    transformedX = pca.transform(DMSO_Wells)\n",
    "    weightedPCA = np.multiply(transformedX, pca.explained_variance_ratio_)\n",
    "    \n",
    "    all_mahala_distances = []\n",
    "    for i in range(0, 10000):\n",
    "        np.random.shuffle(weightedPCA)\n",
    "\n",
    "        treatments = weightedPCA[0:num_pseudo_treatments]\n",
    "        control = weightedPCA[num_pseudo_treatments:]\n",
    "\n",
    "        x = []\n",
    "        for i in range(0, use_components):\n",
    "            x.append(np.mean(treatments[:, i]))\n",
    "\n",
    "        u = []\n",
    "        for i in range(0, use_components):\n",
    "            u.append(np.mean(control[:, i]))\n",
    "\n",
    "        covariance_treatment = np.cov(treatments, rowvar=0)\n",
    "        covariance_control = np.cov(control, rowvar=0)\n",
    "\n",
    "        weighted_covariance_treatment = covariance_treatment * (float(len(treatments)) / (len(treatments) + len(control)))\n",
    "        weighted_covariance_control = covariance_control * (float(len(control)) / (len(treatments) + len(control)))\n",
    "\n",
    "        S = weighted_covariance_treatment + weighted_covariance_control\n",
    "\n",
    "        S = np.cov(weightedPCA, rowvar=0)\n",
    "\n",
    "        x = np.array(x)\n",
    "        u = np.array(u)\n",
    "        distance_rand = mahalanobis(x, u, np.linalg.inv(S))\n",
    "        all_mahala_distances.append(distance_rand)\n",
    "    \n",
    "    \n",
    "    return all_mahala_distances\n",
    "    \n",
    "#If the random DMSO distances were already calculated load pre-calculated distances\n",
    "if os.path.isfile('../results/Calculate_Interactions/RandomMahalanobisDistances_DMSO.pickle'):\n",
    "    pickle_in = open('../results/Calculate_Interactions/RandomMahalanobisDistances_DMSO.pickle',\"rb\")\n",
    "    Mahalanobis_Random_Distribution = pickle.load(pickle_in)\n",
    "else:\n",
    "    #\n",
    "    # Since there are more than 20k points of DMSO, the theoretically added 3-6 single perturbation points would not add too much but cost massive additionaly computaion time\n",
    "    \n",
    "    #Create Random Mahalanobis distributions for k = 1, 3,4,5,6,7 (1 = combination, 3-7 singles)\n",
    "    Mahalanobis_Random_Distribution = {'Batch1':{},'Batch2':{}}\n",
    "    for i in range(3,8):\n",
    "        Mahalanobis_Random_Distribution['Batch1'][i] = make_Random_Distribution_DMSO(dmso['Batch1'],i)\n",
    "    Mahalanobis_Random_Distribution['Batch1'][1] = make_Random_Distribution_DMSO(dmso['Batch1'],1)\n",
    "    print 'Finished Batch1 Random Distribution'\n",
    "    for i in range(3,8):\n",
    "        Mahalanobis_Random_Distribution['Batch2'][i] = make_Random_Distribution_DMSO(dmso['Batch2'],i)\n",
    "    Mahalanobis_Random_Distribution['Batch2'][1] = make_Random_Distribution_DMSO(dmso['Batch2'],1)\n",
    "    print 'Finished Batch2 Random Distribution'\n",
    "\n",
    "    #save the results as pickle\n",
    "    pickle_out = open('../results/Calculate_Interactions/RandomMahalanobisDistances_DMSO.pickle',\"wb\")\n",
    "    pickle.dump(Mahalanobis_Random_Distribution, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_MahalanobisDistance(k,numberTreatment,number_of_RandomTries=10000, usePreComputedRandomDistribution = True, batch = None):\n",
    "    '''\n",
    "    This function takes a list of feature vectors, sorted with the first n (numberTreatment) belong to group A and the afterwards to group B.\n",
    "    1.) First the dimension of the feature vectors is reduced using PCA\n",
    "    2.) Only the m PCA dimensions are used so taht at least 90% of all variance is explained\n",
    "    3.) The indivudal dimensions are weighted by their importance\n",
    "    4.) Create the Mean Vector for the two grups (mean over columns)\n",
    "    5.) Calculate the Mahalanobis distance\n",
    "    6.) Calculate an empirical PValue by randomly permuting the labels of the groups and creating a random expected mahalanobis distance distribution; compare real mahalanobis distance\n",
    "        to this randomly drawn distribution to calulate a p value (basically: NumberOfRandomDrawn MahalanobisDistance larger than real / number of random Mahalanobis Distances)\n",
    "    '''\n",
    "    #Fit a PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(k)\n",
    "\n",
    "    #Take only as many principel components so taht 90% of the variance can be explained\n",
    "    variances = pca.explained_variance_ratio_\n",
    "    \n",
    "    total = 0\n",
    "    use_components = 0\n",
    "    for v in variances:\n",
    "        total = total + v\n",
    "        use_components += 1\n",
    "        if total > 0.9:\n",
    "            break\n",
    "\n",
    "    #Use at least 2 components\n",
    "    if use_components <= 1:\n",
    "        use_components = 2\n",
    "    \n",
    "\n",
    "    \n",
    "    #Fit the space to the selected amount of components and transform the data\n",
    "    pca = PCA(n_components=use_components)\n",
    "    pca.fit(k)\n",
    "    transformedX = pca.transform(k)\n",
    "\n",
    "    #weight the dimensions regarding the amount of variance explained\n",
    "    weightedPCA = np.multiply(transformedX, pca.explained_variance_ratio_)\n",
    "\n",
    "    \n",
    "    pca1 = list(weightedPCA[:, 0])\n",
    "    pca2 = list(weightedPCA[:, 1])\n",
    "    \n",
    "    #split the list into the two groups (treated/untreated)\n",
    "    treatments = weightedPCA[0:numberTreatment]\n",
    "    control = weightedPCA[numberTreatment:]\n",
    "    \n",
    "    \n",
    "    #Contains the main treatment vector (Calculate mean vector - Over Columns)\n",
    "    x = []\n",
    "    for i in range(0, use_components):\n",
    "        x.append(np.mean(treatments[:, i]))\n",
    "\n",
    "    #Contains the mean untreated vector (Calculate mean vector - Over Columns)\n",
    "    u = []\n",
    "    for i in range(0, use_components):\n",
    "        u.append(np.mean(control[:, i]))\n",
    "\n",
    "    \n",
    "        \n",
    "    #Create the covariance matrix, as well as the groupA (treatment) mean vector and\n",
    "    # groupB (untreated) mean vector to finally calucate the mahalanobis distance between this two groups\n",
    "    S = np.cov(weightedPCA, rowvar=0)\n",
    "    x = np.array(x)\n",
    "    u = np.array(u)\n",
    "\n",
    "    \n",
    "    #Calculate the Mahalanobis distance between treated and untreated\n",
    "    distance_calc = mahalanobis(x, u, np.linalg.inv(S))\n",
    "\n",
    "    #original = weightedPCA.copy()\n",
    "    treatment_row = weightedPCA[0:numberTreatment].copy()\n",
    "\n",
    "    #typically use pre computed distribution (marginally difference but much faster)\n",
    "    if usePreComputedRandomDistribution == True:\n",
    "        all_mahala_distances = Mahalanobis_Random_Distribution[batch][numberTreatment]\n",
    "    else:\n",
    "        \n",
    "        #in case you stay with the at the time computation: calculate a random mahalanobis distance k times and compare with real mahalanobis distance\n",
    "        \n",
    "        all_mahala_distances = []\n",
    "        for i in range(0, number_of_RandomTries):\n",
    "            np.random.shuffle(weightedPCA)\n",
    "\n",
    "\n",
    "            #if np.array_equal(original, weightedPCA):\n",
    "            if np.array_equal(treatment_row,weightedPCA[0:numberTreatment]):\n",
    "                continue\n",
    "\n",
    "            treatments = weightedPCA[0:numberTreatment]\n",
    "            control = weightedPCA[numberTreatment:]\n",
    "\n",
    "            x = []\n",
    "            for i in range(0, use_components):\n",
    "                x.append(np.mean(treatments[:, i]))\n",
    "\n",
    "            u = []\n",
    "            for i in range(0, use_components):\n",
    "                u.append(np.mean(control[:, i]))\n",
    "\n",
    "                \n",
    "            #Calculate random mahalanobis distance\n",
    "            covariance_treatment = np.cov(treatments, rowvar=0)\n",
    "            covariance_control = np.cov(control, rowvar=0)\n",
    "\n",
    "            weighted_covariance_treatment = covariance_treatment * (float(len(treatments)) / (len(treatments) + len(control)))\n",
    "            weighted_covariance_control = covariance_control * (float(len(control)) / (len(treatments) + len(control)))\n",
    "\n",
    "            S = weighted_covariance_treatment + weighted_covariance_control\n",
    "\n",
    "            S = np.cov(weightedPCA, rowvar=0)\n",
    "\n",
    "            x = np.array(x)\n",
    "            u = np.array(u)\n",
    "            distance_rand = mahalanobis(x, u, np.linalg.inv(S))\n",
    "            \n",
    "            #add to all random\n",
    "            all_mahala_distances.append(distance_rand)\n",
    "\n",
    "    #caluclate empirical pvalue\n",
    "    mp = len([x for x in all_mahala_distances if x >= distance_calc]) / float(len(all_mahala_distances))        \n",
    "    if mp > 1:\n",
    "        mp = 1\n",
    "\n",
    "    \n",
    "    return distance_calc, mp, pca1, pca2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "## LOAD SINGLES i.e. if not yet calculated, compute the significance (mahalanobis) values for each single drug treatment\n",
    "###\n",
    "\n",
    "\n",
    "print \"Load singles:\"\n",
    "\n",
    "#set the perturbation significance level\n",
    "perturbaion_significance = 7\n",
    "\n",
    "#save signficance (MP_Value is deprecated)\n",
    "Single_Drug_Significance = {}\n",
    "\n",
    "#If this file already exists it doesn't need to be calculated again (if you wish to recalculate it you need to delete it first)\n",
    "if os.path.isfile('../results/Calculate_Interactions/Singles/Overview.csv'):\n",
    "    fp = open('../results/Calculate_Interactions/Singles/Overview.csv','r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        Single_Drug_Significance[tmp[0]] = {'Batch1':{},'Batch2':{}}\n",
    "        \n",
    "        if tmp[1] == 'No_Cells':\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['Mahalanobis_Distance'] = 'Nan'\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['MP_Value'] = 'Nan'\n",
    "        else:\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['Mahalanobis_Distance'] = float(tmp[1])\n",
    "            Single_Drug_Significance[tmp[0]]['Batch1']['MP_Value'] = float(tmp[2])\n",
    "            \n",
    "        if tmp[3] == 'No_Cells':\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['Mahalanobis_Distance'] = 'Nan'\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['MP_Value'] = 'Nan'\n",
    "        else:\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['Mahalanobis_Distance'] = float(tmp[3])\n",
    "            Single_Drug_Significance[tmp[0]]['Batch2']['MP_Value'] = float(tmp[4])\n",
    "            \n",
    "else:\n",
    "    #Go through all clouds\n",
    "    for cloud in all_all_clouds:\n",
    "        #cloud = 'CLOUD031'\n",
    "        Single_Drug_Significance[cloud] = {}\n",
    "        #calculate the significance for both batches separately\n",
    "        for b in ['Batch1','Batch2']:\n",
    "\n",
    "            #Create a list with Treatments (drug vectors) and DMSO; Including only those perturbations that have enough cells\n",
    "            \n",
    "            #Get the single perturbations\n",
    "            \n",
    "            if drug_vectors_WithoutOutliers[b].has_key(cloud):\n",
    "                k = drug_vectors_WithoutOutliers[b][cloud].values()\n",
    "                numberTreatment = len(k)\n",
    "            else:\n",
    "                numberTreatment = 0\n",
    "            \n",
    "            \n",
    "            #Only perform an analysis if at least 3 replicates exist\n",
    "            if numberTreatment < 3 or cloud in drugs_to_remove[b] or cloud in killing_drugs[b]:\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':'LessThanThreeWells','MP_Value':'LessThanThreeWells'}\n",
    "            elif cloud in killing_drugs[b]:\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':'TooFewCells','MP_Value':'TooFewCells'}\n",
    "            elif cloud in drugs_to_remove[b]:\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':'DrugDecay','MP_Value':'DrugDecay'}\n",
    "            else:\n",
    "                #if enough replicates, add the DMSO wells to the list\n",
    "                k.extend(dmso[b])\n",
    "\n",
    "                #Calculate the mahalanobis distance as well as empirical pValue.\n",
    "                distance_calc, mp, pca1, pca2 = Calculate_MahalanobisDistance(k,numberTreatment,usePreComputedRandomDistribution=True,batch=b)\n",
    "                \n",
    "\n",
    "                '''\n",
    "                PLOT RESULTS\n",
    "                '''\n",
    "                if distance_calc >  perturbaion_significance:\n",
    "                    color = ['#b2182b']*numberTreatment\n",
    "                else:\n",
    "                     color = ['#2166ac']*numberTreatment\n",
    "\n",
    "                for i in range(1,len(k)):\n",
    "                    color.append('grey')\n",
    "\n",
    "                Single_Drug_Significance[cloud][b] = {'Mahalanobis_Distance':distance_calc,'MP_Value':mp}\n",
    "\n",
    "                plt.scatter(pca1[numberTreatment:], pca2[numberTreatment:], c=color[numberTreatment:], alpha=0.4)\n",
    "                plt.scatter(pca1[0:numberTreatment], pca2[0:numberTreatment], c=color[0:numberTreatment], alpha=0.4)\n",
    "                plt.legend(['DMSO','Mahalanobis Distance: %.2f\\nn = %d' % (distance_calc,numberTreatment)])\n",
    "                #plt.show()\n",
    "                plt.savefig('../results/Calculate_Interactions/Singles/'+cloud+'_'+b+'.pdf')\n",
    "                plt.close()\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    WRITE OUTPUT\n",
    "    '''\n",
    "    fp_out = open('../results/Calculate_Interactions/Singles/Overview.csv','w')\n",
    "    fp_out.write('Drug,Batch1_Mahalanobis_Distance,Batch1_MP_Value,Batch2_Mahalanobis_Distance,Batch2_MP_Value\\n')\n",
    "    for cloud in all_all_clouds:\n",
    "        fp_out.write(cloud+','+str(Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'])+','+str(Single_Drug_Significance[cloud]['Batch1']['MP_Value'])+','+str(Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'])+','+str(Single_Drug_Significance[cloud]['Batch2']['MP_Value'])+'\\n')\n",
    "    fp_out.close()\n",
    "\n",
    "\n",
    "#print Single_Drug_Significance\n",
    "print 'Number of significant drugs in Batch1: %d' %len([x for x in Single_Drug_Significance if Single_Drug_Significance[x]['Batch1']['Mahalanobis_Distance'] > perturbaion_significance and Single_Drug_Significance[x]['Batch2']['Mahalanobis_Distance']  != 'Nan'])\n",
    "print 'Number of significant drugs in Batch2: %d' %len([x for x in Single_Drug_Significance if Single_Drug_Significance[x]['Batch2']['Mahalanobis_Distance'] > perturbaion_significance and Single_Drug_Significance[x]['Batch2']['Mahalanobis_Distance']  != 'Nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a distribution over all perturbations; use mean over both batches\n",
    "mahalanobis_distances = []\n",
    "for cloud in All_CLOUDs:\n",
    "    \n",
    "    values = []\n",
    "    if Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'] != 'No_Cells' and Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'] != 'Nan':\n",
    "        values.append(Single_Drug_Significance[cloud]['Batch1']['Mahalanobis_Distance'])\n",
    "    if Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'] != 'No_Cells'  and Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'] != 'Nan':\n",
    "        values.append(Single_Drug_Significance[cloud]['Batch2']['Mahalanobis_Distance'])\n",
    "    \n",
    "    if len(values) > 0:\n",
    "        mahalanobis_distances.append(max(values))\n",
    "\n",
    "\n",
    "##\n",
    "# PLOT OUTPUT\n",
    "##\n",
    "print 'Number at least once significant: %d' %len([x for x in mahalanobis_distances if x > 7])\n",
    "print 'Number never  significant: %d' %len([x for x in mahalanobis_distances if x <= 7])\n",
    "plt.hist(mahalanobis_distances,bins=15, color='#40B9D4')\n",
    "plt.axvline(7, color='grey', ls='--')\n",
    "#plt.show()\n",
    "plt.savefig('../results/Calculate_Interactions/Singles/Overview_Histogram.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate Interactions\n",
    "Calculate the actual interaction between all drug pairs. Include only drug pairs where both singles as well as the combination fullfill all quality control criteria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of DMSO wells after a (MAD=2) outlier detection; these will serve as random intracellular fluctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dictonary will contain the 15-32 DMSO wells of each plate\n",
    "dmso_wells_Outlier_Removed = {'Batch1':{},'Batch2':{}}\n",
    "\n",
    "#Go through both batches\n",
    "for b in ['Batch1','Batch2']:\n",
    "    #get all plates of this batch\n",
    "    plates = list(set([x.split(',')[2] for x in drug_perturbation_vectors[b].keys()]))\n",
    "    #go through all plates\n",
    "    for plate in plates:\n",
    "        \n",
    "        #Get corresponding DMSO wells of this plate\n",
    "        DMSO_Wells  = [drug_perturbation_vectors[b][x] for x in drug_perturbation_vectors[b] if 'DMSO,None,'+str(plate) in x and well_cell_count[x]['Number'] > cutoff_min_cells]\n",
    "        DMSO_Wells = np.array(DMSO_Wells)\n",
    "        \n",
    "        #Perform outlier detection\n",
    "        DMSO_EucledianDistances = []\n",
    "        DMSO_values = []\n",
    "        for s1_a in DMSO_Wells:\n",
    "            tmp = []\n",
    "            for s1_b in DMSO_Wells:\n",
    "                sim = np.linalg.norm(s1_a - s1_b) \n",
    "                tmp.append(sim)\n",
    "\n",
    "            DMSO_EucledianDistances.append(np.mean(tmp))\n",
    "            DMSO_values.append(s1_a)\n",
    "        \n",
    "        #Perform actual MAD outlier detection with MAD = 10\n",
    "        good_rows = reject_outliers_2(DMSO_EucledianDistances,2)\n",
    "        keep_values = [DMSO_values[x] for x in range(0,len(DMSO_values)) if good_rows[x]]\n",
    "        \n",
    "        #Add result\n",
    "        dmso_wells_Outlier_Removed[b][plate] = keep_values\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "##Actual Math for calculating the DDIs##\n",
    "########################################\n",
    "\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "def calculate_vector_math_v2(a, b, c):\n",
    "    '''\n",
    "    calculate the amount of single a, single b, and the 'surprise factor)\n",
    "    :param a: vector a (single)\n",
    "    :param b: vector b (single)\n",
    "    :param c: vector c (combination)\n",
    "    :return: alpha, beta and gamma (part of vector a, b and suprise)\n",
    "    '''\n",
    "\n",
    "    if sum(a) != 0 and sum(b) != 0:\n",
    "\n",
    "        \n",
    "        #Check first for two special cases:\n",
    "        \n",
    "        # 1.\n",
    "        #Check if angle between the two vectors is to narrow (both point in same direction)\n",
    "        if angle_between(a,b) <= 0.5:\n",
    "            #h = c/(a+b)\n",
    "\n",
    "            A=  np.array([[np.dot(a, a), np.dot(a, b)], [np.dot(a, b), np.dot(b, b)]])\n",
    "            h = np.array([np.dot(a, c), np.dot(b, c)])\n",
    "\n",
    "            alpha = h[0] / (A[0][0]+A[1][0])\n",
    "            beta = h[1]  / (A[0][1]+A[1][1])\n",
    "\n",
    "            n =alpha * a + beta * b - c\n",
    "\n",
    "            gamma = np.linalg.norm(n)\n",
    "            return str(alpha),str(beta),str(gamma)\n",
    "        \n",
    "        # 2. \n",
    "        #Check if angle between two is EXACTLY 180 degrees\n",
    "        elif angle_between(a,b) == 3.141592653589793:\n",
    "            A = np.array([[np.dot(a, a), np.dot(a, b)], [np.dot(a, b), np.dot(b, b)]])\n",
    "            h = np.array([np.dot(a, c), np.dot(b, c)])\n",
    "\n",
    "\n",
    "            alpha = h[0] / (A[0][0] + abs(A[1][0]))\n",
    "            beta = h[1]  / (abs(A[0][1]) + A[1][1])\n",
    "\n",
    "            n = alpha * a + beta * b - c\n",
    "\n",
    "            gamma = np.linalg.norm(n)\n",
    "\n",
    "            return str(alpha), str(beta), str(gamma)\n",
    "\n",
    "    try:\n",
    "\n",
    "        #\n",
    "        # Check if all or any of the 3 vectors is zero\n",
    "        \n",
    "        if sum(c) != 0 and sum(a) == 0 and sum(b) == 0:\n",
    "            return '1','1',str(dis.euclidean([0]*len(c),c))\n",
    "        elif sum(c) == 0 and sum(a) == 0 and sum(b) == 0:\n",
    "            return '1','1','0'\n",
    "        elif sum(c) == 0 and sum(a) == 0:\n",
    "            return '1','0','0'\n",
    "        elif sum(c) == 0 and sum(b) == 0:\n",
    "            return '0','1','0'\n",
    "\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            # Matrix equation\n",
    "            A = np.array([[np.dot(a, a), np.dot(a, b)], [np.dot(a, b), np.dot(b, b)]])\n",
    "\n",
    "            h = np.array([np.dot(a, c), np.dot(b, c)])\n",
    "\n",
    "            \n",
    "            if A[0][0]==0 and h[0] ==0: #one vector zero, so combination can be only 1dim\n",
    "\n",
    "                beta = h[1]/A[1][1]\n",
    "                n = beta * b -c\n",
    "                gamma = np.linalg.norm(n)\n",
    "\n",
    "                if  (len(list(b)) - list(b).count(0) > 2) or np.linalg.norm(b) > 0.5:\n",
    "                    return '1.0',str(beta),str(gamma)\n",
    "                else:\n",
    "                    return '1', '1', str(dis.euclidean([0] * len(c), c))\n",
    "            elif A[1][1]==0 and h[1] ==0:\n",
    "                alpha = h[0]/A[0][0]\n",
    "                n = alpha * a -c\n",
    "                gamma = np.linalg.norm(n)\n",
    "\n",
    "\n",
    "                if len(list(a)) - list(a).count(0) > 2 or np.linalg.norm(a) > 0.5:\n",
    "                    return str(alpha),'1',str(gamma)\n",
    "                else:\n",
    "                    return '1', '1', str(dis.euclidean([0] * len(c), c))\n",
    "            elif h[0] == 0 and h[1] == 0:\n",
    "                gamma = np.linalg.norm(c)\n",
    "                return '0.0','0.0',str(gamma)\n",
    "            elif A[0][0] != 0 and h[0] == 0 and h[1] == 0:\n",
    "                gamma = np.linalg.norm(c)\n",
    "                return '0.0','1.0',str(gamma)\n",
    "            elif A[1][1] != 0 and h[0] == 0 and h[1] == 0:\n",
    "                gamma = np.linalg.norm(c)\n",
    "                return '1.0','0',str(gamma)\n",
    "\n",
    "            \n",
    "            ##########################\n",
    "            # The ideal normal case with 3 vectors in correct angle and not being zero\n",
    "            ##########################\n",
    "            \n",
    "            p = np.linalg.solve(A, h)\n",
    "            # orthogonal vector\n",
    "            n = p[0] * a + p[1] * b - c\n",
    "\n",
    "            distance = np.linalg.norm(n)\n",
    "            # check\n",
    "            # print('dot product of a and c: %.4f' %(np.dot(a,n)))\n",
    "            # print('dot product of b and c: %.4f' %(np.dot(b,n)))\n",
    "            # print('distance: %.3f' %(distance))\n",
    "            return str(p[0]), str(p[1]), str(distance)\n",
    "    except:\n",
    "        return 'Error', 'Error', 'Error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate possible interactions for all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLISS RESULT FILE\n",
    "fp_out = open('../results/Calculate_Interactions/Bliss_Scores_Cytotoxicity.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,Plate,Well,S1,S2,C,Expected,Difference\\n')\n",
    "\n",
    "#MC RESULT FILE - Menche-Caldera Score\n",
    "fp_out2 = open('../results/Calculate_Interactions/MC_Scores.csv','w')\n",
    "fp_out2.write('Drug1,Drug2,Batch,Plate,Well,S1_Mahalanobis,S1_MPValue,S1_Norm,S2_Mahalanobis,S2_MPValue,S2_Norm,Combi_Mahalanobis,Combi_MPValue,Combi_Norm_Norm,Alpha,Beta,Gamma,Alpha_Zero,Beta_Zero,Gamma_Zero,Mahalanobis_Distance_To_NI,MPValue_To_NI\\n')\n",
    "\n",
    "\n",
    "#Results of the combination significances\n",
    "Combination_Drug_Significance = {}\n",
    "\n",
    "#Go through all pairs\n",
    "for cloud1 in All_CLOUDs:\n",
    "    for cloud2 in All_CLOUDs:\n",
    "        # A|B = B|A\n",
    "        if cloud1 > cloud2:\n",
    "\n",
    "            \n",
    "            #Get the combination well\n",
    "            combination_well =  [x for x in well_cell_count if cloud1+','+cloud2 in x or cloud2+','+cloud1 in x]\n",
    "            \n",
    "            #This should never happen\n",
    "            if len(combination_well) == 0:\n",
    "                print 'Problem!!!'\n",
    "            \n",
    "            #Extract the plate and well information\n",
    "            plate = combination_well[0].split(',')[2]\n",
    "            well = combination_well[0].split(',')[3]\n",
    "                         \n",
    "            #Extract the batch information from the plate number\n",
    "            if int(plate) < 1315065:\n",
    "                b = 'Batch1'\n",
    "            else:\n",
    "                b= 'Batch2'\n",
    "            \n",
    "            #Check if either for the two drugs are in the drugs_to_remove list ==> all this interactions must be discarded (e.g. because the drug oxidized over course of screen)\n",
    "            \n",
    "            #Get the single replicates\n",
    "            single1_replicate_wells = [x for x in drug_perturbation_vectors[b] if cloud1+',DMSO' in x]\n",
    "            single2_replicate_wells = [x for x in drug_perturbation_vectors[b] if cloud2+',DMSO' in x]\n",
    "\n",
    "            #Get the Combination well cell count, and the transfer status\n",
    "            combi_Number =  well_cell_count[combination_well[0]]['Number']\n",
    "            combi_Worked =  well_cell_count[combination_well[0]]['Worked']\n",
    "            \n",
    "            #Get the singles cell counts\n",
    "            s1_cellCount = [well_cell_count[x]['Number'] for x in single1_replicate_wells if well_cell_count[x]['Worked'] == 'TRUE']\n",
    "            s2_cellCount = [well_cell_count[x]['Number'] for x in single2_replicate_wells if well_cell_count[x]['Worked'] == 'TRUE']\n",
    "            \n",
    "            \n",
    "            #If there was a problem with the drug transfer ===> all this interactions must be discarded (i.e. because no drug was transfered in this well)\n",
    "            if combi_Worked == 'FALSE':\n",
    "                fp_out.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CombinationTransferProblem']*5)+'\\n')\n",
    "                fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CombinationTransferProblem']*17)+'\\n')\n",
    "\n",
    "            else:\n",
    "                \n",
    "                '''\n",
    "                Perform CellCount Analysis:\n",
    "                Calculate Bliss Score: E (Expected)= s1 + s2 - s1*s2; S (Score) = c - E \n",
    "                The actual score is the combination cytotoxicity minus what is expected.\n",
    "                '''\n",
    "               \n",
    "                #Remove obvious outliers\n",
    "                s1_cellCount_check = reject_outliers_2(s1_cellCount)\n",
    "                s1_cellCount = [s1_cellCount[x] for x in range(0,len(s1_cellCount)) if s1_cellCount_check[x]]\n",
    "                s2_cellCount_check = reject_outliers_2(s2_cellCount)\n",
    "                s2_cellCount = [s2_cellCount[x] for x in range(0,len(s2_cellCount)) if s2_cellCount_check[x]]\n",
    "\n",
    "                #Calculate the s1, s2 and c cytotoxicity; If the drug wells have even more cells than the DMSO control cytotoxicity is set to 0\n",
    "                #Drug1\n",
    "                s1_cytotoxicity = (DMSO_CellCount[b] -  np.mean(s1_cellCount))/DMSO_CellCount[b]\n",
    "                #print s1_cytotoxicity\n",
    "                if s1_cytotoxicity < 0:\n",
    "                    s1_cytotoxicity = 0\n",
    "                    \n",
    "                #Drug2\n",
    "                s2_cytotoxicity = (DMSO_CellCount[b] -  np.mean(s2_cellCount))/DMSO_CellCount[b]\n",
    "                if s2_cytotoxicity < 0:\n",
    "                    s2_cytotoxicity = 0\n",
    "\n",
    "                #Combination\n",
    "                comb_cytotoxicity = (DMSO_CellCount[b] -  combi_Number)/DMSO_CellCount[b]\n",
    "                if comb_cytotoxicity < 0:\n",
    "                    comb_cytotoxicity = 0\n",
    "                \n",
    "                               \n",
    "                #Calculate the expected value (E); if e.g. both drug kill all cells the sum should also be only 100% and not 200%\n",
    "                Bliss_expected = s1_cytotoxicity + s2_cytotoxicity - s1_cytotoxicity*s2_cytotoxicity\n",
    "                if Bliss_expected > 1:\n",
    "                    Bliss_expected = 1\n",
    "                                     \n",
    "                # Calculate the actual score by substracting expected value from the combination cytotoxicity.\n",
    "                # POSITIVE values indicate cytotoxic syngergy while NEGATIVE values indicate cytotoxic antagony\n",
    "                Bliss_Difference = comb_cytotoxicity - Bliss_expected\n",
    "                \n",
    "                #Write results to output\n",
    "                fp_out.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+str(s1_cytotoxicity)+','+str(s2_cytotoxicity)+','+str(comb_cytotoxicity)+','+str(Bliss_expected)+','+str(Bliss_Difference)+'\\n')\n",
    "\n",
    "                #Check if one of the singles is a cytotoxic drug (i.e. has too few cells in the well) or the combination is cytotoxic\n",
    "                if cloud1 in killing_drugs[b]:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicDrug1']*17)+'\\n')\n",
    "                    continue\n",
    "                if cloud2 in killing_drugs[b]:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicDrug2']*17)+'\\n')\n",
    "                    continue\n",
    "                if combi_Number < cutoff_min_cells:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicCombination']*17)+'\\n')\n",
    "                    continue\n",
    "                \n",
    "                '''\n",
    "                MORPHOLOGY - MC SCORE CALCULATION\n",
    "                '''\n",
    "                    \n",
    "                #################\n",
    "                # FROM HERE actual morphology\n",
    "                # 1.) check if the two singles and/or combination are significant morphological changers\n",
    "                # 2.) depending on that calculate interactions\n",
    "                ###########\n",
    "                \n",
    "                \n",
    "                #Check if combination feature vector exist (if not there might have been a problem with the well; e.g. filtered for bad quality)\n",
    "                if drug_perturbation_vectors[b].has_key(combination_well[0]) == False:\n",
    "                    fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['ProblemWithCombinationWell']*17)+'\\n')\n",
    "                    continue\n",
    "                \n",
    "                #Get the combination vector\n",
    "                combi_Vector =  drug_perturbation_vectors[b][combination_well[0]]\n",
    "                \n",
    "                \n",
    "                # since only 1 replicate for combination k = only combi_Vector\n",
    "                k = [combi_Vector]\n",
    "                # number treatment = 1\n",
    "                numberTreatment = len(k)\n",
    "                # add ALL DMSO controls over the whole batch found  > 2k dmso wells\n",
    "                k.extend(dmso[b])\n",
    "\n",
    "\n",
    "                #Calculate the mahalanobis distance as well as empirical pValue (later not used in final paper)\n",
    "                combination_distance_calc, combination_mp, pca1, pca2 = Calculate_MahalanobisDistance(k,numberTreatment,usePreComputedRandomDistribution=True,batch=b)\n",
    "            \n",
    "                #Calculate the vector length (=norm)\n",
    "                Combi_VectorNorm = np.linalg.norm(combi_Vector)\n",
    "            \n",
    "                #Get the significance of drug1 and drug2\n",
    "                s1_Mahalanobis = Single_Drug_Significance[cloud1][b]['Mahalanobis_Distance'] \n",
    "                s1_MValue = Single_Drug_Significance[cloud1][b]['MP_Value'] \n",
    "                s2_Mahalanobis = Single_Drug_Significance[cloud2][b]['Mahalanobis_Distance'] \n",
    "                s2_MValue = Single_Drug_Significance[cloud2][b]['MP_Value'] \n",
    "            \n",
    "                #\n",
    "                # Load the single vectors and calculate the MEAN vector for the respective replicates\n",
    "                #\n",
    "                \n",
    "                ########\n",
    "                # SINGLE 1\n",
    "                #check if drug1 is significant (single1)\n",
    "                s1_significant = False\n",
    "                if s1_Mahalanobis > 7:\n",
    "                    s1_significant = True\n",
    "                s1_Vectors = drug_vectors_WithoutOutliers[b][cloud1].values()     \n",
    "\n",
    "                #Create a numpy array\n",
    "                val =  np.array(s1_Vectors)\n",
    "\n",
    "                #Transform into mean vector\n",
    "                s1_MeanVector = []\n",
    "                for i in range(0,numfeatures):\n",
    "                    s1_MeanVector.append(np.mean(val[:,i]))\n",
    "\n",
    "                #get s1 vector length (=norm)\n",
    "                s1_Mean_VectorNorm = np.linalg.norm(s1_MeanVector)\n",
    "\n",
    "                ########\n",
    "                # SINGLE 2\n",
    "                #check if drug2 is significant (single2)\n",
    "                s2_significant = False\n",
    "                if  s2_Mahalanobis > 7:\n",
    "                    s2_significant = True\n",
    "                s2_Vectors = drug_vectors_WithoutOutliers[b][cloud2].values()    \n",
    "\n",
    "                #Create a numpy array\n",
    "                val =  np.array(s2_Vectors)\n",
    "\n",
    "                #Transform into mean vector\n",
    "                s2_MeanVector = []\n",
    "                for i in range(0,numfeatures):\n",
    "                    s2_MeanVector.append(np.mean(val[:,i]))\n",
    "\n",
    "                #get s2 vector length (=norm)\n",
    "                s2_Mean_VectorNorm = np.linalg.norm(s2_MeanVector)\n",
    "\n",
    "                ########\n",
    "                # Combination\n",
    "                #check if combination is significant; no need to create a mean vector as only one replicate\n",
    "                comb_significant = False\n",
    "                if combination_distance_calc > 7:\n",
    "                    comb_significant = True\n",
    "\n",
    "                #Only if at least one of the three players is significantly perturbed\n",
    "                #if no_interaction == False: \n",
    "\n",
    "                #Transform the three lists into numpy arrays\n",
    "                s1_MeanVector_toCalculate = np.array(s1_MeanVector)\n",
    "                s2_MeanVector_toCalculate = np.array(s2_MeanVector)\n",
    "                comb_MeanVector_toCalculate = np.array(combi_Vector)              \n",
    "\n",
    "                #Calculate alpha/beta/gamma\n",
    "                alpha,beta,gamma = calculate_vector_math_v2(s1_MeanVector_toCalculate,s2_MeanVector_toCalculate,comb_MeanVector_toCalculate)\n",
    "\n",
    "\n",
    "                '''\n",
    "                Additionally one can also set non significant vector to the NULL vectors (then the math is forced to only use significant ones)\n",
    "                '''\n",
    "\n",
    "                if s1_significant == False:\n",
    "                    s1_MeanVector_toCalculate = np.array([0]*numfeatures)                                \n",
    "                if s2_significant == False:\n",
    "                    s2_MeanVector_toCalculate = np.array([0]*numfeatures)                      \n",
    "                if comb_significant == False:\n",
    "                    comb_MeanVector_toCalculate = np.array([0]*numfeatures)\n",
    "\n",
    "                \n",
    "                #Calculate alpha_0/beta_0/gamma_0 (not used in final version)\n",
    "                alpha_0,beta_0,gamma_0 = calculate_vector_math_v2(s1_MeanVector_toCalculate,s2_MeanVector_toCalculate,comb_MeanVector_toCalculate)\n",
    "\n",
    "\n",
    "                '''\n",
    "                CHECK IF THE INTERACTION IS SIGNIFICANT\n",
    "                1. Calculate all possible vector sums of the single vectors\n",
    "                2. Add intracellular plate variability by adding DMSO vectors\n",
    "                3. Calculate the pValue and the Mahalanobis distance of the interaction to this 'possible vector sums'\n",
    "                '''\n",
    "                \n",
    "                \n",
    "                #Get DMSO wells (of this plate) after outlier detection (these serve ONLY as an ADDITIONAL cell fluctation that is added to all NI (vector sums))\n",
    "                DMSO_Wells = dmso_wells_Outlier_Removed[b][plate]\n",
    "\n",
    "                #Calculate all possible NIs and add the DMSO cell fluctuation to them (randomly choose 10 DMSO)\n",
    "                possible_results = []\n",
    "                for s1 in s1_Vectors:\n",
    "                    tmp = []\n",
    "                    for s2 in s2_Vectors:\n",
    "                        vector_sum = np.array(s1) + np.array(s2)\n",
    "                        possible_results.append(vector_sum)\n",
    "                        #random_DMSO_Wells = random.sample(DMSO_Wells,25)\n",
    "                        for DMSO_well in DMSO_Wells:\n",
    "                            possible_results.append(vector_sum+np.array(DMSO_well))\n",
    "\n",
    "                k = list(possible_results)\n",
    "                k.insert(0,combi_Vector)\n",
    "                #Here 500 random tries is already enough since only ca. 250 datapoints in 'possible' results\n",
    "                combination_distance_calc_toNI, combination_mp_toNI, _, _ = Calculate_MahalanobisDistance(k,numberTreatment,number_of_RandomTries = 10000, usePreComputedRandomDistribution = False)\n",
    "\n",
    "\n",
    "                #Make a PCA plot if it is a significant interaction\n",
    "                if combination_distance_calc_toNI > 3:\n",
    "\n",
    "                    #number of all points\n",
    "                    number_vectorsums = len(k)\n",
    "\n",
    "                    #colorize combination\n",
    "                    color = ['#b2182b']*numberTreatment\n",
    "                    for i in range(1,len(k)):\n",
    "                        color.append('blue')\n",
    "\n",
    "                    #add DMSO_Wells (for that plate); color = grey\n",
    "                    k.extend(DMSO_Wells)\n",
    "                    for i in range(0,len(DMSO_Wells)):\n",
    "                        color.append('grey')\n",
    "\n",
    "                    #add and color vector1\n",
    "                    k.extend(s1_Vectors)\n",
    "                    for i in range(0,len(s1_Vectors)):\n",
    "                        color.append('#e08214')\n",
    "                    \n",
    "                    #add and color vector2\n",
    "                    k.extend(s2_Vectors)\n",
    "                    for i in range(0,len(s2_Vectors)):\n",
    "                        color.append('#5aae61')\n",
    "\n",
    "                    #Perform PCA dimension reduction\n",
    "                    pca = PCA(n_components=2)\n",
    "                    pca_vals = pca.fit_transform(k)\n",
    "\n",
    "                    #add labels\n",
    "                    if s1_significant:\n",
    "                        cloud1_name = cloud1 +'(+)'\n",
    "                    else:\n",
    "                        cloud1_name = cloud1 +'(-)'\n",
    "\n",
    "                    if s2_significant:\n",
    "                        cloud2_name = cloud2 +'(+)'\n",
    "                    else:\n",
    "                        cloud2_name = cloud2 +'(-)'\n",
    "\n",
    "\n",
    "                    #Create Legend\n",
    "                    legend_elements = [Patch(facecolor='#b2182b', lw=1,\n",
    "                                         label='Combination\\nMahalanobis Distance: %.2f\\n mp = %.2e' % (combination_distance_calc_toNI, combination_mp_toNI)),\n",
    "                                       Patch(facecolor='blue', \n",
    "                                         label='Vector_Sums'),\n",
    "                                       Patch(facecolor='grey', \n",
    "                                         label='DMSO'),\n",
    "                                       Patch(facecolor='#e08214', \n",
    "                                         label=cloud1_name),\n",
    "                                       Patch(facecolor='#5aae61', \n",
    "                                         label=cloud2_name)]\n",
    "\n",
    "                    plt.figure(figsize=(5,5))\n",
    "                    #Plot possible vector sums\n",
    "                    sns.kdeplot(pca_vals[:, 0][1:number_vectorsums], pca_vals[:, 1][1:number_vectorsums], n_levels=8,cmap=\"Blues\",alpha=0.6,gridsize = 100,shade=True, shade_lowest=False,  bw='scott', kernel='gau' )\n",
    "                    #Plot DMSO, Single1 and Single2\n",
    "                    plt.scatter(pca_vals[:, 0][number_vectorsums:], pca_vals[:, 1][number_vectorsums:], c=color[number_vectorsums:], alpha=0.6)\n",
    "                    #Plot Combination\n",
    "                    plt.scatter(pca_vals[:, 0][0], pca_vals[:, 1][0], c=color[0], alpha=1)\n",
    "                    #Plot Legend\n",
    "                    plt.legend(handles=legend_elements, loc='best', prop={'size': 7})\n",
    "                    plt.xlim([min(pca_vals[:, 0]) - 0.1, max(pca_vals[:, 0])+0.1])\n",
    "                    plt.ylim([min(pca_vals[:, 1]) - 0.1, max(pca_vals[:, 1])+0.1])\n",
    "                    plt.xlabel('PC1 [%.2f]' %(pca.explained_variance_ratio_[0]))\n",
    "                    plt.ylabel('PC2 [%.2f]' %(pca.explained_variance_ratio_[1]))\n",
    "                    plt.savefig('../results/Calculate_Interactions/Combinations/'+cloud1+'_'+cloud2+'.png')\n",
    "                    plt.close()\n",
    "\n",
    "                #Write output\n",
    "                fp_out2.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+str(s1_Mahalanobis)+','+str(s1_MValue)+','+str(s1_Mean_VectorNorm) +','+str(s2_Mahalanobis)+','+str(s2_MValue)+','+str(s2_Mean_VectorNorm)+','+str(combination_distance_calc)+','+str(combination_mp)+','+str(Combi_VectorNorm)+','+str(alpha)+','+str(beta)+','+str(gamma)+','+str(alpha_0)+','+str(beta_0)+','+str(gamma_0)+','+str(combination_distance_calc_toNI)+','+str(combination_mp_toNI) +'\\n')\n",
    "#Close file pointers                       \n",
    "fp_out.close()\n",
    "fp_out2.close()\n",
    "\n",
    "print 'Created all interactions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repair interaction files\n",
    "In case something has to be added or removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "mypath = '../results/Calculate_Interactions/MC_Scores/'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "for file in onlyfiles:\n",
    "    print file\n",
    "    fp_out = open('../results/Calculate_Interactions/MC_ScoresNew/'+file,'w')\n",
    "    \n",
    "    fp = open(mypath+file)\n",
    "\n",
    "    fp_out.write(fp.readline())\n",
    "    for line in fp:\n",
    "        tmp = line.strip().split(',')\n",
    "        \n",
    "        cloud1 = tmp[0]\n",
    "        cloud2 = tmp[1]\n",
    "        b = tmp[2]\n",
    "        plate = tmp[3]\n",
    "        well = tmp[4]\n",
    "        \n",
    "        combination_well =  [x for x in well_cell_count if cloud1+','+cloud2 in x or cloud2+','+cloud1 in x]\n",
    "        combi_Number =  well_cell_count[combination_well[0]]['Number']\n",
    "        \n",
    "        if combi_Number < cutoff_min_cells:\n",
    "             fp_out.write(cloud1+','+cloud2+','+str(b)+','+plate+','+well+','+','.join(['CytotoxicDrug']*19)+'\\n')\n",
    "        else:\n",
    "            fp_out.write(line)\n",
    "    fp.close()\n",
    "    fp_out.close()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all files\n",
    "This is only important if a computer cluster or any other tool is used to calculate the individual results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Make Summary File'\n",
    "print 'MC_Scores:'\n",
    "MC_Score_Files = [f for f in os.listdir('../results/Calculate_Interactions/MC_Scores/') if os.path.isfile(os.path.join('../results/Calculate_Interactions/MC_Scores/', f))]\n",
    "MC_Score_Files.sort()\n",
    "fp_out = open('../results/Calculate_Interactions/All_MC_Scores.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,Plate,Well,S1_Mahalanobis,S1_MPValue,S1_Norm,S2_Mahalanobis,S2_MPValue,S2_Norm,Combi_Mahalanobis,Combi_MPValue,Combi_Norm_Norm,Alpha,Beta,Gamma,Alpha_Zero,Beta_Zero,Gamma_Zero,DistanceFromOrigin,Mahalanobis_Distance_To_NI,MPValue_To_NI\\n')\n",
    "for file_name in MC_Score_Files:\n",
    "    fp = open('../results/Calculate_Interactions/MC_Scores/'+file_name,'r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        fp_out.write(line)\n",
    "    fp.close()\n",
    "fp_out.close()\n",
    "print 'Done'\n",
    "\n",
    "print 'Bliss_Scores:'\n",
    "Bliss_Score_Files = [f for f in os.listdir('../results/Calculate_Interactions/Bliss_Scores/') if os.path.isfile(os.path.join('../results/Calculate_Interactions/Bliss_Scores/', f))]\n",
    "Bliss_Score_Files.sort()\n",
    "fp_out = open('../results/Calculate_Interactions/All_Bliss_Scores.csv','w')\n",
    "fp_out.write('Drug1,Drug2,Batch,Plate,Well,S1,S2,C,Expected,Difference\\n')\n",
    "for file_name in Bliss_Score_Files:\n",
    "    fp = open('../results/Calculate_Interactions/Bliss_Scores/'+file_name,'r')\n",
    "    fp.next()\n",
    "    for line in fp:\n",
    "        fp_out.write(line)\n",
    "    fp.close()\n",
    "fp_out.close()\n",
    "print 'Done'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
